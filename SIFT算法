// SIFT Algorithm.cpp : 定义控制台应用程序的入口点。
//
//分析opencv中keypoint数据结构的相关信息，可以看到数据结构中有如下
//angle：角度，表示关键点的方向，为了保证方向不变形，SIFT算法通过对关键点周围邻域进行梯度运算，求得该点方向。
//class_id：当要对图片进行分类时，我们可以用class_id对每个特征点进行区分，未设定时为-1，
//octave：代表是从金字塔哪一层提取的得到的数据。
//pt：关键点点的坐标
//response：响应程度，代表该点强壮大小，是该点角点的程度。
//size：该点直径的大小
//
//注意一个问题：keypoint只是保存了opencv的sift库检测到的特征点的一些基本信息，但sift所提取出来的特征向量其实不是在这个里面，
//特征向量通过SiftDescriptorExtractor 提取，结果放在一个Mat的数据结构中。这个数据结构才真正保存了该特征点所对应的特征向量。
//具体见后文对SiftDescriptorExtractor 所生成的对象的详解。
//
//我们知道opencv下自带SIFT特征检测以及MATCH匹配的库，这些库完全可以让我们进行傻瓜似的操作。
//但实际用起来的时候还不是那么简单。下文将对一个典型的基于OPENCV的SIFT特征点提取以及匹配的例程进行分析，
//并由此分析详细的对OPENCV中SIFT算法的使用进行一个介绍。
//
//OPENCV下SIFT特征点提取与匹配的大致流程如下：
//读取图片-》
//特征点检测（位置，角度，层）-》
//特征点描述的提取（16*8维的特征向量）-》
//匹配-》
//显示
//1、使用opencv内置的库读取两幅图片
//2、生成一个SiftFeatureDetector的对象，这个对象顾名思义就是SIFT特征的探测器，用它来探测衣服图片中SIFT点的特征，
//存到一个KeyPoint类型的vector中。keypoint只是保存了opencv的sift库检测到的特征点的一些基本信息，
//但sift所提取出来的特征向量其实不是在这个里面，
//特征向量通过SiftDescriptorExtractor 提取，结果放在一个Mat的数据结构中。这个数据结构才真正保存了该特征点所对应的特征向量。
//3、对图像所有KEYPOINT提取其特征向量：
//得到keypoint只是达到了关键点的位置，方向等信息，并无该特征点的特征向量，要想提取得到特征向量就还要进行SiftDescriptorExtractor 的工作，
//建立了SiftDescriptorExtractor对象后，通过该对象，对之前SIFT产生的特征点进行遍历，找到该特征点所对应的128维特征向量。
//具体方法参见opencv中SiftDescriptorExtractor所做的SIFT特征向量提取工作简单分析。
//通过这一步后，所有keypoint关键点的特征向量被保存到了一个MAT的数据结构中，作为特征。
//4、对两幅图的特征向量进行匹配，得到匹配值。
//两幅图片的特征向量被提取出来后，我们就可以使用BruteForceMatcher对象对两幅图片的descriptor进行匹配，
//得到匹配的结果到matches中
#include "stdafx.h"
#include"opencv2/opencv.hpp"
#include"highgui/highgui.hpp"
#include"opencv2/nonfree/nonfree.hpp"
#include"opencv2/legacy/legacy.hpp"
#include<iostream>
using namespace cv;
using namespace std;
int main(int argc,char**argv){
       Mat src_Img1 =imread("F:\\PHOTO\\image01.jpg");
       Mat src_Img2 =imread("F:\\PHOTO\\image02.jpg");
       imshow("输入图像1",src_Img1);
       imshow("输入图像2",src_Img2);
       Mat gray_Img01 ,gray_Img02;
       //转为灰度图像
       cvtColor(src_Img1,gray_Img01,CV_BGR2GRAY);
       cvtColor(src_Img2,gray_Img02,CV_BGR2GRAY);
       //提取特征点
       vector<KeyPoint> keyPoint01,keyPoint02;
       //SIFT特征的探测器
       //探测200个特征点
       SiftFeatureDetector mySiftDetector(200);
       //将探测的200个简要的特征点信息存入 keyPoint 集合中，keypoint只是保存了特征点的一些基本信息，但sift所提取出来的特征向量其实不是在这个里面，
    //特征向量需要通过SiftDescriptorExtractor 提取，结果放在一个Mat的数据结构中。这个数据结构才真正保存了该特征点所对应的特征向量。
       mySiftDetector.detect(gray_Img01,keyPoint01);
       mySiftDetector.detect(gray_Img02,keyPoint02);
       //特征描述
       SiftDescriptorExtractor mySiftDescriptorExtractor;
       Mat descriptorImg01,descriptorImg02;
       //从原图像中，根据keyPoint提供的基础信息，寻找相应的特征向量，保存在mat 类型的文件中。
       mySiftDescriptorExtractor.compute(gray_Img01,keyPoint01,descriptorImg01);
       mySiftDescriptorExtractor.compute(gray_Img02,keyPoint02,descriptorImg02);
       
       //特征匹配（使用快速近似最近邻域搜索算法）
    //使用FLANN进行匹配
   //实例化一个FLANN匹配器(括号里可以选择匹配方法)
       FlannBasedMatcher myFlannBasedMatcher;
       // DMatch是用来描述匹配好的一对特征点的类，包含这两个点之间的匹配信息
    //比如左图有个特征m，它和右图的特征点n最匹配，这个DMatch就记录它俩最匹配，
    //并且还记录m和n的特征向量的距离和其他信息
       
       vector<vector<DMatch>> matchPoints; 
       //筛选比较好的匹配点
       vector<DMatch> goodMatcherPoints;
       vector<Mat> train_desc(1,descriptorImg01);
       myFlannBasedMatcher.add(train_desc);
       myFlannBasedMatcher.train();
       myFlannBasedMatcher.knnMatch(descriptorImg02,matchPoints,2);
       cout<<"total match points:"<<matchPoints.size()<<endl;
       //获取优秀匹配点
       for (int i=0;i<matchPoints.size();i++){
              if(matchPoints[i][0].distance<0.6*matchPoints[i][1].distance){
              goodMatcherPoints.push_back(matchPoints[i][0]);
              }
       }
       Mat matcherImg;
       drawMatches(src_Img2,keyPoint02,src_Img1,keyPoint01,goodMatcherPoints,matcherImg);
       imshow("matcherImg",matcherImg);
       waitKey(0);
       return 0;
}
